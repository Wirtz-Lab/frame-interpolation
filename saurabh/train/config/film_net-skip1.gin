model.name = 'film_net'

film_net.pyramid_levels = 7
film_net.fusion_pyramid_levels = 5
film_net.specialized_levels = 3
film_net.sub_levels = 4
film_net.flow_convs = [3, 3, 3, 3]
film_net.flow_filters = [32, 64, 128, 256]
film_net.filters = 64

training.learning_rate = 0.0001
training.learning_rate_decay_steps = 750000
training.learning_rate_decay_rate = 0.464158
training.learning_rate_staircase = True
# change this
training.num_steps = 6000

# change this
training_dataset.file = r'\\fatherserverdw\Saurabh\Saurabh\Pancreas_Ashley_Files\training_tiles_triplet_v2\sequences.tfrecord@3'
training_dataset.batch_size = 8
training_dataset.crop_size = 256

eval_datasets.batch_size = 1
eval_datasets.max_examples = -1
eval_datasets.files = [r'\\fatherserverdw\Saurabh\Saurabh\Pancreas_Ashley_Files\test_tiles_triplet_v2\sequences.tfrecord@1']
eval_datasets.names = ['skip1']

# Training augmentation (in addition to random crop)
data_augmentation.names = ['random_image_rot90', 'random_flip', 'random_rotate', 'random_reverse']

# Loss functions
training_losses.loss_names = ['l1', 'vgg', 'style']
training_losses.loss_weight_schedules = [
    @tf.keras.optimizers.schedules.PiecewiseConstantDecay,
    @tf.keras.optimizers.schedules.PiecewiseConstantDecay,
    @tf.keras.optimizers.schedules.PiecewiseConstantDecay]
# Increase the weight of style loss at 1.5M steps.
training_losses.loss_weight_parameters = [
    {'boundaries':[0], 'values':[1.0, 1.0]},
    {'boundaries':[1500000], 'values':[1.0, 0.25]},
    {'boundaries':[1500000], 'values':[0.0, 40.0]}]

test_losses.loss_names = ['l1', 'psnr', 'ssim']
test_losses.loss_weights = [1.0, 1.0, 1.0]

vgg.vgg_model_file = r'\\shelter\Kyu\motility_interpolation\pretrained_models\vgg\imagenet-vgg-verydeep-19.mat'
style.vgg_model_file = r'\\shelter\Kyu\motility_interpolation\pretrained_models\vgg\imagenet-vgg-verydeep-19.mat'
